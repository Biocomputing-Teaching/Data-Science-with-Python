{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT 9. Convolutional Neural Networks on the MNIST dataset\n",
    "\n",
    "This Unit includes an implementation of a CNN to calssify digits from the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database). Code adapted from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":style: unsrt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we start by importing:\n",
    "* the dataset *MNIST*\n",
    "* the **[Sequential](https://keras.io/guides/sequential_model/)** function\n",
    "* the differential layers:\n",
    "  * **[Conv2D](https://towardsdatascience.com/conv2d-to-finally-understand-what-happens-in-the-forward-pass-1bbaafb0b148)**: creates the convolutional kernel to produce a set of output features\n",
    "  * **[MaxPooling2D](https://deepai.org/machine-learning-glossary-and-terms/max-pooling)**: downsamples the input by taking the maximum value of the kernel, reducing the dimensionality of the model\n",
    "  * **Flatten**: flattens the input tensor into a one dimensional vector. Useful when transitioning from a CNN to a fully connected CNN\n",
    "  * **Dense**: standard fully connected NN layer. Each neuron in the layer is connected to all neurons in the previous layer. \n",
    "* **to_categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us now load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us display a collection of sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAFHCAYAAADeJlTJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlHElEQVR4nO3deZzO9frH8WuQdWzDhKEh2ZIsWUJ+Y1osWUKbZJc4dj2O5VhiHGKqo3NERIoskSXEMVEZlKW06CSUFruMbZgZ4jjm90en61y37mnmNnPf33t5PR8Pj8d77rnnvq9xzz0un8/38/mEpaenpwsAAAhpuZwuAAAAOI+GAAAA0BAAAAAaAgAAIDQEAABAaAgAAIDQEAAAAKEhAAAAQkMAAAAkSBqCzZs3S1hYmNs/O3fudLq8kJaamipDhw6VqKgoyZ8/v9SuXVuWLl3qdFlwY+7cuRIWFibh4eFOlxLSUlJSZMSIEdK8eXOJjIyUsLAwiYuLc7osiMinn34qLVq0kMKFC0t4eLjce++9sm3bNqfLyjFB0RD8ZvLkybJjxw6XPzVq1HC6rJD28MMPy5tvvinjx4+XhIQEqV+/vnTq1Eneeustp0uDcezYMRk2bJhERUU5XUrIO3PmjMyZM0cuX74s7du3d7oc/NeuXbskJiZGLl26JAsXLpSFCxfKL7/8Ivfff7/s2LHD6fJyRFgwnGWwefNmuffee2X58uXy6KOPOl0O/mv9+vXSunVreeutt6RTp056e/PmzeWbb76Rw4cPS+7cuR2sEL9p27athIWFSUREhKxYsUJSU1OdLilk/fYrOSwsTE6fPi2RkZEyfvx4Rgkc1rJlS9m9e7f8+OOPUrBgQRH5dTSnYsWKUqVKlaAYKQiqEQL4l1WrVkl4eLg89thjLrf37NlTjh8/Lp988olDlcFatGiRbNmyRWbOnOl0KRDR6U74l23btklsbKw2AyIihQsXlpiYGNm+fbucOHHCwepyRlA1BAMGDJA8efJIkSJFpEWLFvLxxx87XVJI27Nnj9x+++2SJ08el9tr1qypn4ezkpKSZOjQoRIfHy/lypVzuhzAb125ckXy5cv3u9t/u+3rr7/2dUk5LigagqJFi8qQIUNk9uzZkpiYKNOmTZMjR45IbGysbNiwwenyQtaZM2ckIiLid7f/dtuZM2d8XRKu079/f6latar069fP6VIAv1a9enXZuXOnXLt2TW+7evWqjnQGw++zPJnfxf/VqVNH6tSpox//3//9n3To0EHuvPNOGTFihLRo0cLB6kLbHw19MizqrJUrV8ratWvlyy+/5LUAMjFo0CB56qmnZODAgTJmzBi5du2aTJgwQQ4dOiQiIrlyBf7/rwP/O8hAsWLFpE2bNvKvf/1LLl265HQ5IalEiRJuu+azZ8+KiLgdPYBvpKamyoABA2TQoEESFRUlycnJkpycLFeuXBERkeTkZElLS3O4SsB/9OrVS+Lj42XhwoVSrlw5iY6Olr1798qwYcNERKRs2bIOV5h9QdsQiLherQvfu/POO2Xfvn1y9epVl9t/m2tjSahzTp8+LSdPnpSpU6dK8eLF9c+SJUskLS1NihcvLp07d3a6TMCvjBw5Uk6fPi1ff/21HDx4ULZv3y7nzp2TQoUKSd26dZ0uL9uCYsrAnXPnzsm6deukdu3akj9/fqfLCUkdOnSQ1157TVauXCkdO3bU2998802JioqSu+++28HqQlvp0qUlMTHxd7fHx8fLli1bJCEhQUqWLOlAZYB/y5cvn/5n5vDhw/L222/L008/LQUKFHC4suwLiobgySeflOjoaKlXr56ULFlSDhw4IFOnTpWTJ0/K/PnznS4vZD344IPSrFkz6devn1y4cEEqVaokS5Yskffee08WLVrEHgQOyp8/v8TGxv7u9vnz50vu3Lndfg6+k5CQIGlpaZKSkiIiInv37pUVK1aIiEirVq1clr7BN/bs2SMrV66UevXqSb58+eSrr76S+Ph4qVy5skycONHp8nJGehCYMmVKeu3atdOLFi2anjt37vTIyMj0Dh06pH/66adOlxbyUlJS0gcPHpxeunTp9Lx586bXrFkzfcmSJU6XhQx07949vVChQk6XEfLKly+fLiJu//z0009OlxeSvv322/SYmJj0iIiI9Lx586ZXqlQpfezYsempqalOl5ZjgmKnQgAAkD1BfVEhAADIGhoCAABAQwAAAGgIAACA0BAAAAChIQAAAEJDAAAAxIOdCjkPwDtyYhsIXhvvyO5rw+viHbxn/BfvGf+U1deFEQIAAEBDAAAAaAgAAIDQEAAAAKEhAAAAQkMAAACEhgAAAAgNAQAAEBoCAAAgNAQAAEA82LoYyGl169bVPHDgQM3dunXTvGDBAs3Tp0/X/MUXX3i5OgAILYwQAAAAGgIAACASlp7FY5D88RSq3Llzay5atGim97fD0gULFtRctWpVzQMGDND8t7/9TXOnTp1cHuuXX37RHB8fr3nChAmZ1mGF2slttWvX1rxp0ybNRYoUyfRrz58/r7lEiRI5Wpc7nNzmufvvv1/z4sWLXT7XtGlTzd9+++0NP0eovWc8NXbsWM3291GuXP/7/19sbKzL12zZsiVHnpv3jH/itEMAAJBlNAQAAMC/VhlER0drzps3r+bGjRtrbtKkieZixYppfuSRR274eY8ePar55Zdf1tyhQwfNKSkpLl/z1Vdfac6p4bZg1aBBA80rV67UbKd57JCW/bu+cuWKZjtN0LBhQ83XrziwXxNIYmJiNNvvddWqVU6Uc0Pq16+vedeuXQ5WElp69OiheeTIkZqvXbvm9v45Me2C4MMIAQAAoCEAAAAOTxnYK85FXK86z8qqgeywQ2n2qtzU1FTN9irpEydOuHz9uXPnNGfniulgYldu3HXXXZoXLVqkuUyZMpk+zoEDBzS/8MILmpcuXap527Ztmu3rJyIyZcqULFbsX+yV35UrV9bs71MG9ur1W2+9VXP58uVd7scV5N5j/67z58/vYCXB5+6779bcpUsXzXbVzB133OH2a4cNG6b5+PHjmu3Ut/39+Mknn2Sv2GxihAAAANAQAAAAGgIAACAOX0Nw+PBhl4/PnDmjOTvXENh5mOTkZM333nuvZrs0beHChTf8XPif2bNna75+Z0dP2OsPwsPDNdvlnXa+vWbNmjf8XP7EHuq0Y8cOByvxjL0u5Omnn9Zs50ZFRPbv3++zmkLBAw88oHnQoEFu72P/ztu0aaP55MmT3issCHTs2FHztGnTNJcsWVKzvSZm8+bNmiMjIzW/+OKLbh/ffq29/xNPPHFjBecQRggAAAANAQAAcHjK4OzZsy4fDx8+XLMd3vryyy81250Erd27d2tu1qyZ5rS0NM12aciQIUM8Lxi/U7duXc2tW7fWnNESMzvsv3btWs32ICm7PMe+9nap53333ZfpcwUau3wvkMydO9ft7Xb5KHKGXa42b948zRlNsdoh60OHDnmvsACVJ8///gmsV6+e5tdee02zXU69detWzRMnTtT88ccfa86XL5/mZcuWaW7evLnbGj777DNPy/aawPwNBAAAchQNAQAA8K/DjVavXq3Z7lpoD7upVauW5qeeekqzHXK20wTWN998o7lPnz7ZqjWU2R0m33//fc1FihTRbA9PSUhI0GxXH9idvuxug3YI+tSpU5rtgVJ2p0k7VSHiukrh+oOP/I1dIVGqVCkHK7lxGQ1X258N5Izu3btrjoqKcnsfe8X7ggULvF1SQLM7D2Y09WV/ju3qgwsXLri9v71PRtME9kC9N998M2vF+gAjBAAAgIYAAAD42ZSBldFwzPnz593ebjdEefvttzVndB44PFOlShXNdjWIHS4+ffq0ZnsYlB0Ss4dH/fOf/3SbPVWgQAGXj//85z9r7ty58w0/ri+0atVK8/Xfhz+z0xv2QCPr2LFjvionqNnNcHr16qXZ/m6zG7BNmjTJJ3UFKrs6YPTo0ZrtNOfMmTM12+nMjP5dssaMGZPpfQYPHqzZTos6jRECAABAQwAAAPx4yiAjcXFxmu2mOPaKdbvH98aNG31SV7Cxm2uIuK7isMPcdgWI3Yvfbrbh66Hw6Ohonz5fdlStWtXt7XZFjD+yPw92+uC7777TbH824JkKFSpoXrlyZab3nz59uubExERvlBSwxo0b5/KxnSawZ9ps2LBB88iRIzVfunTJ7ePmz59fs11NYH//2E3T7FTOmjVrslS7rzFCAAAAaAgAAEAAThnYTYfsygK7AY3dh9oOn9lh7FdeeUWzvboUv6pTp47Lx3aawGrXrp1me04BsmfXrl2OPbfdYKply5aa7SYuGW24Yq/gtle+wzP27z2j470//PBDzfaIXogUK1ZMc//+/V0+Z3/f22mC9u3bZ/q4lSpV0rx48WLNdvraWrFiheYXXngh08d3GiMEAACAhgAAAATglIH1ww8/aO7Ro4dmeyxo165d3eZChQpptvt92w11QtlLL73k8rG9WtZODTg1TWCPCg7GzaciIiI8/hp7zod9veyqm3LlymnOmzevZruBk/27tVdYf/LJJ5ovX76s2R4h+/nnn3tcN35lh6zj4+Pd3sces2vPNchow7ZQZX+27cZO17MbBN18882ae/bsqfmhhx7SXKNGDc3h4eGa7TSEzYsWLdKc0Rk7/oQRAgAAQEMAAAACfMrAWrVqleYDBw5otkPf999/v+bJkydrLl++vObnnntOc6jtxd6mTRvN9ohjEddhsHfffddXJWXIThNcv0pk9+7dPq7mxtkheft9vPrqq5rtRip/xF6NbqcMrl69qvnixYua9+7dq/mNN97QbFfj2CmhkydParbHt9qNp/bv35+lWvErTzcg+vHHHzXb1wOu7IZD158VEBkZqfmnn37SnJXVZsePH9dszzUoU6aMZnumy9q1a7NYsX9ghAAAANAQAACAIJoysPbs2aP58ccf19y2bVvNdiVC3759NVeuXFlzs2bNvFWiX7JDv/YqXRGRpKQkzfZ4aW+zZyrYcyysTZs2uXw8atQob5aUo+ymKYcOHdLcuHFjjx/r8OHDmlevXq153759mnfu3Onx4/6mT58+mu2wqx3GhmfsnvlZWS2T0eoDuLKbYl2/4dC6des029U8dtWaPWtg/vz5ms+ePat56dKlmu2Ugb090DBCAAAAaAgAAECQThlYduho4cKFmufOnavZbqwSExOjOTY2VvPmzZu9Ul+gsBvReHvzJjtNMHbsWM3Dhw/XbK9ynzp1qsvXp6amerE673n++eedLuEP2VU6Vlaujsf/2BU8GZ0JYdnh62+//dYbJQU1u6GWiOt0l6fsvw9NmzbVbKd7AnkKjRECAABAQwAAAIJ0ysBu0PLoo49qrl+/vmY7TWDZzVq2bt3qheoCk7c3I7LDqHZqoGPHjprt0Okjjzzi1XqQdXZTMGRu48aNmosXL+72PnY1iD2nBc6yK7Ey2hyNVQYAACCg0RAAAIDAnjKoWrWq5oEDB2p++OGHNZcuXTrTx/nPf/6j2V5BH4zH6v4Ru/+9zSKum3sMGTIkR57vmWee0fzss89qLlq0qObFixdr7tatW448L+CkEiVKaM7od8zMmTM1B+qqmWC0YcMGp0vwKkYIAAAADQEAAAiQKQM77N+pUyfNdprAHiOaFfaIV3vksT8c7esUe6Xs9UeB2tfg5Zdf1myPzT1z5ozmhg0bau7atavmWrVqaS5Xrpxmuw+/HZazQ6fwH3ZKqUqVKpqzc1ZCMLNnp+TKlfn/w7Zv3+7NcnCDWrRo4XQJXsUIAQAAoCEAAAB+NmVQqlQpzdWrV9c8Y8YMzdWqVfPoMe0+1i+++KJmu8lNqK0muBG5c+fWbI/stRsEXbhwQbM9Rjojdlg0MTFR87hx4264TviGnVLKyhB4KLKbbT3wwAOa7e+bK1euaH7llVc0nzx50rvF4YZUrFjR6RK8incyAACgIQAAADQEAABAHLiGICIiQvPs2bNdPmfn3Dydq7Hz0VOnTtVsl7BdunTJo8cMNTt27NC8a9cul8/Zg6EsuxzRXgNi2eWI9uCPnNrxEM5q1KiR5vnz5ztXiJ8pVqyY5ox2TD127JjmYcOGebskZNNHH32k2V47EyzXoTFCAAAAaAgAAIAXpwzuvvtuzfZ8+wYNGmguW7asx4978eJFzXbHvMmTJ2tOS0vz+HEhcvToUc32gCgRkb59+2oeO3Zspo81bdo0zbNmzdL8/fffZ6dE+InrD78CQsGePXs0HzhwQLOd4r7ttts0nzp1yjeF5RBGCAAAAA0BAADw4pRBhw4d3OY/snfvXs3r1q3TfPXqVc12BUFycnI2KsQfOXHihMvHcXFxbjNCR0JCgubHHnvMwUoCw/79+zXbVVBNmjRxohzkMDtNPXfuXM32sLxBgwZptv+++StGCAAAAA0BAAAQCUu//uD7jO7IVcVekcW//j/Ea+Md2X1teF28g/eM/wql90yRIkU0L1u2TLM9yOqdd97R3LNnT82+XgmX1deFEQIAAEBDAAAAmDJwHMOf/iuUhj8DCe8Z/xWq7xk7fWBXGfTr109zzZo1Nft6xQFTBgAAIMtoCAAAAFMGTmP403+F6vCnv+M94794z/gnpgwAAECW0RAAAICsTxkAAIDgxQgBAACgIQAAADQEAABAaAgAAIDQEAAAAKEhAAAAQkMAAACEhgAAAAgNAQAAEBoCAAAgNAQAAEBoCAAAgNAQAAAAoSEAAABCQwAAAISGAAAACA0BAAAQGgIAACA0BAAAQGgIAACA0BAAAAChIQAAAEJDAAAAhIYAAAAIDQEAABAaAgAAIDQEAABAaAgAAIDQEAAAAKEhAAAAQkMAAACEhgAAAAgNAQAAEBoCAAAgNAQAAEBoCAAAgNAQAAAAoSEAAABCQwAAAISGAAAACA0BAAAQGgIAACA0BAAAQGgIAACA0BAAAAChIQAAAEJDAAAAhIYAAAAIDQEAABAaAgAAIDQEAABAaAgAAIDQEAAAAKEhAAAAQkMAAACEhgAAAAgNAQAAEBoCAAAgNAQAAEBoCAAAgNAQAAAAoSEAAABCQwAAAISGAAAACA0BAAAQGgIAACA0BAAAQGgIAACA0BAAAAChIQAAAEJDAAAAhIYAAAAIDQEAABAaAgAAIDQEAABAaAgAAIDQEAAAAKEhAAAAQkMAAACEhgAAAAgNAQAAEBoCAAAgNAQAAEBoCAAAgNAQAAAAoSEAAABCQwAAAISGAAAACA0BAAAQGgIAACA0BAAAQGgIAACA0BAAAAChIQAAAEJDAAAAhIYAAABIkDQEmzZtkl69ekm1atWkUKFCUrZsWWnXrp18/vnnTpcW8lJSUmTEiBHSvHlziYyMlLCwMImLi3O6rJC3e/duad26tURHR0uBAgUkIiJCGjVqJIsWLXK6tJDHeyZwzJ07V8LCwiQ8PNzpUnJEUDQEs2bNkoMHD8qQIUNk/fr1Mm3aNElKSpKGDRvKpk2bnC4vpJ05c0bmzJkjly9flvbt2ztdDv4rOTlZbrnlFpk8ebKsX79eFixYIBUqVJCuXbvKpEmTnC4vpPGeCQzHjh2TYcOGSVRUlNOl5Jiw9PT0dKeLyK6kpCS5+eabXW5LTU2VSpUqSY0aNeSDDz5wqDL89uMVFhYmp0+flsjISBk/fjz/4/FTDRs2lOPHj8vhw4edLiVk8Z4JDG3btpWwsDCJiIiQFStWSGpqqtMlZVtQjBBc3wyIiISHh0v16tXlyJEjDlSE34SFhUlYWJjTZSCLSpYsKXny5HG6jJDGe8b/LVq0SLZs2SIzZ850upQcFbTv/PPnz8sXX3wh9913n9OlAH7r2rVrcu3aNTl37pwsX75cNmzYIDNmzHC6LMBvJSUlydChQyU+Pl7KlSvndDk5KmgbggEDBkhaWpqMGTPG6VIAv9W/f3+ZPXu2iIjkzZtXXn75Zenbt6/DVQH+q3///lK1alXp16+f06XkuKBsCJ599llZvHixTJ8+XerWret0OYDfGj16tPTu3VuSkpJk7dq1MnDgQElLS5Nhw4Y5XRrgd1auXClr166VL7/8MiindYKuIZgwYYJMmjRJnnvuORk4cKDT5QB+LTo6WqKjo0VEpFWrViIiMmrUKOnevbtERkY6WRrgV1JTU2XAgAEyaNAgiYqKkuTkZBERuXLlioj8unLnpptukkKFCjlYZfYExUWFv5kwYYLExcVJXFycjB492ulygIDToEEDuXr1qvz4449OlwL4ldOnT8vJkydl6tSpUrx4cf2zZMkSSUtLk+LFi0vnzp2dLjNbgmaEYOLEiRIXFydjx46V8ePHO10OEJASExMlV65cUrFiRadLAfxK6dKlJTEx8Xe3x8fHy5YtWyQhIUFKlizpQGU5JygagqlTp8q4ceOkZcuW0rp1a9m5c6fL5xs2bOhQZRARSUhIkLS0NElJSRERkb1798qKFStE5Ndh6oIFCzpZXkjq06ePFClSRBo0aCClSpWS06dPy/Lly+Xtt9+W4cOHM13gMN4z/id//vwSGxv7u9vnz58vuXPndvu5QBMUGxPFxsbKli1bMvx8EHyLAa1ChQpy6NAht5/76aefpEKFCr4tCDJv3jyZN2+e7Nu3T5KTkyU8PFxq1aolvXv3li5dujhdXsjjPRM4evToETQbEwVFQwAAALInqC4qBAAAN4aGAAAA0BAAAAAaAgAAIDQEAABAaAgAAIB4sDFRMB7k4A9yYtUnr413ZPe14XXxDt4z/ov3jH/K6uvCCAEAAKAhAAAANAQAAEBoCAAAgNAQAAAAoSEAAABCQwAAAISGAAAACA0BAAAQGgIAACA0BAAAQDw4ywDwxLRp0zQPHjxY8549ezS3adNG86FDh3xTGAAEiA8//FCzPefhvvvu88rzMUIAAABoCAAAQAhMGRQuXFhzeHi45tatW2uOjIzU/NJLL2m+fPmyl6sLLhUqVNDcpUsXzdeuXdN8++23a65WrZpmpgy8p0qVKppvuukmzTExMZpnzpyp2b5enlqzZo3mJ554wuVzV65cueHHDQX2tWncuLHmyZMna77nnnt8WhN86+9//7vLx/bnYMGCBV5/fkYIAAAADQEAAAiiKQM7XD1y5EjNjRo10lyjRo1MH6dMmTKa7dXxyNypU6c0b926VfNDDz3kRDkh54477tDco0cPzY899pjmXLn+93+AqKgozXaaID09/YZrsK/1q6++6vK5oUOHar5w4cINP0ewKlq0qObExETNP//8s+bSpUu7vR2BKz4+XvOf/vQnl8/9+9//1mxXHHgLIwQAAICGAAAABOCUgb0y3Q5Bdu7cWXOBAgU0280cjhw5ojklJUWzvfL98ccf12yvvN6/f382qg4NaWlpmlk14HtTpkzR3KpVKwcr+VW3bt1cPn799dc1b9u2zdflBCw7TcCUQfBp2LChZrvSRETk448/1rxs2TKv18IIAQAAoCEAAAA0BAAAQPz4GgK7BOf555/X3LFjR812F8KMHDhwQHOLFi0027kae31AyZIl3WZkrlixYppr1arlXCEh6v3339ec0TUESUlJmu2cvl2OmNFOhXbXtKZNm95wnfCMvQ4Kvmd39BwzZozmTp06aT579qxHj2m/1i6H/+GHH1zuN2zYMI8eN7sYIQAAADQEAADAj6cMOnTooLl3794efa0ddmnWrJlmu+ywUqVK2agO7hQsWFBzdHR0pvevX7++Zjttw5LFGzNr1izNq1evdnsfu/OZp8vWihQponnPnj2a7Y6H1vU1fPbZZx49H35ld47Mnz+/g5WEpjlz5miuXLmy5urVq2u2ywOzYvTo0ZpLlCih+emnn3a531dffeXR42YXIwQAAICGAAAA+PGUgT2QJSMHDx7UvGvXLs32cCM7TWDZ3QmRM44fP655/vz5muPi4tze396enJysecaMGTlcWWi4evWq5ox+7rPDrtIpXrx4pvc/evSoy8eXL1/O8ZpCTb169TTv3LnTwUpCx8WLFzVnZ/qmdu3amsuXL6/ZrupxekqIEQIAAEBDAAAA/HjKwF5t2adPH80bN27U/P3332u2G65kRalSpbJRHTIzceJEzRlNGcD/PfHEE5rte9IeIJaRcePGeaWmYGWnfM6fP6/ZbtJ22223+bSmUGV/f915552a9+3bpzkrKwAKFSqk2U5l2xVZdupnxYoVnhebgxghAAAANAQAAMCPpwzsFeveGHJu1KhRjj8m3MvKPvlwVufOnTX/5S9/0Ww38Lr+rHZ3du/erdlugoTM2ZU2H330keY2bdo4UE3oueWWWzTb6TE7lTNw4EDNp06dyvQxX3rpJc125Zz99+2ee+7xvFgvYYQAAADQEAAAAD+eMvDU4MGDNdsrOzNirxy1tm/frnnHjh3ZLwwu0wR2Yw/krAoVKmju2rWr5gceeCDTr23SpInmrLxGFy5c0GynGNavX6/50qVLmT4O4CR79PCqVas0lyxZUvP06dM1b9myJdPHtEcW9+jRw+19nnvuOU/K9BlGCAAAAA0BAAAIkCkDu4mDPXJy/Pjxmlu1auX2a7Nyhbu94rNnz56a//Of/3heLOBDdsjz3Xff1ZyV46ezw14Fb4+HhXfZo3KRNXnyuP4z16VLF82vv/665oz+rbAr0kaNGqXZriCIiIjQbFcThIWFaV6wYIHm2bNnZ/0b8CFGCAAAAA0BAADwsykDu/FJnTp1NK9cuVJzmTJlNNurmO2wv10d0LJlS8126sGyQ0oPP/yw5mnTpmm+cuVK5t8A4CA7PGlzVni6eZTdLOfBBx/UnJCQ4NHzwjMPPfSQ0yUEHHseh4jI3LlzNdsVNfbn3p6TY4+ctrldu3aay5Ytq9n+G2U3L+rVq5fHtfsaIwQAAICGAAAAODxlkDdvXpeP7fD+O++84/ZrJkyYoHnTpk2at23bptle8WnvY6/ItiIjIzVPmTJF8+HDhzWvXr3a5WsuX77s9rHwe1kZjo6JidE8Y8YMr9cULPbs2aM5NjZWs72SesOGDZp/+eUXjx7/qaee0jxo0KAbqBA3IjExUTNnGXiuY8eOmufNm+fyOXvGhj0/4sknn9R87tw5zVOnTtXctGlTzXb6wE7R2WkIu8HRkSNHNNv36g8//JDxN+JjjBAAAAAaAgAAIBKWnsXN5T29ajkjdiXBX//6V5fPDR8+3O3X2CuX7R7tdrjHDvvb/dTvuusuzXalwAsvvKDZTiXYK0etDz74wOXj559/XrMdXrLsUbAZyYm9/XPqtfEWu8FTVr7fmjVrat67d69XasqK7L42/v66ZEXRokU1nzlzxu192rZtq9kXqwxC4T3zyCOPaF6+fLlmu7LKbtJ26NAh3xSWCX95z9ip4vLly7t8btKkSZqvn05wx/492w2F7IZFGU0ZWG+99Zbmbt26Zfq8OSmrrwsjBAAAgIYAAAD4aJVB7ty5NU+cOFGzPSZSRCQtLU2zPVJ16dKlmu00gb3K016Zbjc1OnDggOZ+/fpptlfxFilSRHPjxo01d+7cWfP1G4K8//774o69kvTWW291e59Q8+qrr2ru27dvpvfv06eP5qFDh3qjJGRRixYtnC4hJF29etXt7XZoOl++fL4qJ+CsWbNG8/Ur1uzv6KywKwUyWqnWqVMnzXblj3X06FGPntcJjBAAAAAaAgAA4KMpAzsEbKcJLl686HI/O5y8ceNGzQ0bNtRsjye2e6gXKFBAs129YK8izWio6MKFC5rfe+89t9kOCYm4bmJhPfPMM25vD2X79+93uoSAZlfmNG/e3OVz9mpqewV6dtj3mD3PA75jh7zt+6datWqa7XRa//79fVJXoMjuz61dXWOPM7bTy3ZDoWXLlmXr+fwFIwQAAICGAAAA+GhjohMnTmi2Gwhdfx6AHRorVKiQ5kqVKmX6HHFxcZrteQR2Uxx/FAqbrFjfffed5ttuu83tfezZB/a19/We305ustKkSRPNY8aM0dysWTOX+9mVLJ5ePW3P/GjVqpXm6dOnay5cuLDbr7XTE3YFjl294y2h9p75xz/+odlO55QqVUqzp2dUeIu/bEyUXaNGjdJsV8bZ44zr16+v2d9XELAxEQAAyDIaAgAA4JtVBj///LNmO2Vw/cYatWrVcvv19myCrVu3arZHEh88eFCzv08ThLJvvvlGc8WKFd3eJ6MjkkOJ3Wgro81QRERGjBihOSUlxaPnsNMP9syPjIYXN2/erHnWrFmafTFNgF/Z18aezYLss2ce9O7dW7P9O58zZ45mf58muBGMEAAAABoCAABAQwAAAMRH1xDExMRobt++vWY7bykikpSUpPmNN97QfO7cOc3MmwU2OwfXtm1bBysJDvbArpxi34dr167VPGTIEM3+sswt1Nid8tq1a6d51apVTpQTVOyBdfZ6gkWLFmkeP368T2vyNUYIAAAADQEAAPDRToXIWKjtumaH4tatW6f59ttv12y/nypVqmgOpZ0Ka9eurXnQoEGau3fvnp2SXP4O7eFiH330kWY7rZPR2e5OCrX3zPHjxzUXL15cc506dTT7ywFigbxTYUa7E9rDjQJ1aoadCgEAQJbREAAAAKYMnBZqw5+BxF+GP+2Onj169HD53KRJkzTb4WS7i6e9enrNmjWa7Q6igSTU3jNLly7VbKfW7KFShw4d8mlNGfGX9wxcMWUAAACyjIYAAAAwZeC0UBv+DCQMf/on3jP+i/eMf2LKAAAAZBkNAQAAoCEAAAA0BAAAQGgIAACA0BAAAAChIQAAAEJDAAAAxIONiQAAQPBihAAAANAQAAAAGgIAACA0BAAAQGgIAACA0BAAAAChIQAAAEJDAAAAhIYAAACIyP8D+mTc+CnxKIgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(X_train[3],cmap='gray')\n",
    "plt.show()\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(X_train[i],cmap='gray')\n",
    "    plt.title(y_train[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "* Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-normalization data: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "post-normalization data: [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333336\n",
      "  0.6862745  0.10196079 0.6509804  1.         0.96862745 0.49803922\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
      "  0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "  0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19215687 0.93333334 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.9843137\n",
      "  0.3647059  0.32156864 0.32156864 0.21960784 0.15294118 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07058824 0.85882354 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.7764706  0.7137255  0.96862745 0.94509804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
      "  0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05490196 0.00392157 0.6039216\n",
      "  0.99215686 0.3529412  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54509807\n",
      "  0.99215686 0.74509805 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04313726\n",
      "  0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13725491 0.94509804 0.88235295 0.627451   0.42352942 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31764707 0.9411765  0.99215686 0.99215686 0.46666667\n",
      "  0.09803922 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      "  0.5882353  0.10588235 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0627451  0.3647059  0.9882353\n",
      "  0.99215686 0.73333335 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.9764706\n",
      "  0.99215686 0.9764706  0.2509804  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
      "  0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15294118 0.5803922  0.8980392  0.99215686 0.99215686 0.99215686\n",
      "  0.98039216 0.7137255  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09411765 0.44705883\n",
      "  0.8666667  0.99215686 0.99215686 0.99215686 0.99215686 0.7882353\n",
      "  0.30588236 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07058824 0.67058825 0.85882354 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.7647059  0.3137255  0.03529412 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21568628 0.6745098\n",
      "  0.8862745  0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "  0.52156866 0.04313726 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53333336 0.99215686\n",
      "  0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('pre-normalization data:',X_train[0])\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_text = X_test.astype('float32')/255\n",
    "print('post-normalization data:',X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reshape the dataset to be 4D\n",
    "  * `batch_size`: the number of training examples processed\n",
    "  * `height`/`width`: height/width of each input image in pixels\n",
    "  * `channels`: number of color channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.expand_dims(X_train,axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [One hot encoding](https://blog.gopenai.com/one-hot-encoding-for-ml-with-tensorflow-and-keras-50f67ca9681a) using the `to_categorial` function. It converts the data into an integer. In this particular case, the best choice for this dataset would be to apply *sparse categorical crossentropy loss*— for the simple reason that we don’t have to apply one-hot encoding if we use that loss function. However, for the sake of training, we will apply here one hot encoding to use *categorical crossentropy loss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "[7 2 1 ... 4 5 6]\n",
      "(10000, 10)\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_test)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print(y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model architecture\n",
    "\n",
    "* 4 layers (2 [convolutional](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) and 2 Maxpooling)\n",
    "* 1 flattening layer\n",
    "* 1 fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# first layer with 32 filters and a filter size of (3,3)\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=X_train.shape[1:]))\n",
    "# we reduce the size to half with the MaxPooling layer\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "# the third layer uses 64 filters\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "# convert the 2D map to a 1D vector\n",
    "model.add(Flatten())\n",
    "# fully connected layer with 10 output units, as the categories we have. Linear transformation followed by a softmax to finally select one category\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model. We will use the Adam optimizer (Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model,'model.jpg',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us have a look at the different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d_12/kernel:0' shape=(3, 3, 1, 32) dtype=float32, numpy=\n",
      "array([[[[ 0.0717376 ,  0.12769519,  0.08789454,  0.05253138,\n",
      "          -0.11401037, -0.13674393,  0.14176215, -0.03162821,\n",
      "           0.08083284, -0.11815737, -0.09512089,  0.11325438,\n",
      "          -0.05740895,  0.02741964, -0.03588605,  0.05777355,\n",
      "          -0.01218839, -0.06179042,  0.1334251 , -0.09000895,\n",
      "          -0.09403009,  0.10086344,  0.06635694, -0.0880443 ,\n",
      "           0.13914786,  0.0108107 ,  0.03892626,  0.12062512,\n",
      "          -0.01364759,  0.00382094, -0.04765872, -0.1113653 ]],\n",
      "\n",
      "        [[-0.04247792, -0.01092371,  0.09028479,  0.10562329,\n",
      "          -0.02947589, -0.12216106,  0.11181484, -0.03891839,\n",
      "          -0.06762463,  0.05609684, -0.03396688, -0.13659653,\n",
      "           0.08405785,  0.02790622, -0.03921193, -0.00926368,\n",
      "           0.05148487, -0.03984149,  0.13498177, -0.13713032,\n",
      "          -0.07542631, -0.00471647, -0.12538266,  0.11634909,\n",
      "          -0.11422603,  0.02180572,  0.10012202, -0.09765881,\n",
      "          -0.0627704 , -0.03658996,  0.02599122,  0.02928138]],\n",
      "\n",
      "        [[-0.14183368,  0.02241163,  0.1167203 ,  0.10612147,\n",
      "           0.08080322,  0.13784312, -0.00023985,  0.09635523,\n",
      "          -0.08266414, -0.05851087, -0.13844644,  0.08878958,\n",
      "          -0.06163619,  0.07139483,  0.07589813,  0.1372305 ,\n",
      "           0.09599487, -0.02142467, -0.12904494,  0.08588304,\n",
      "           0.02212006,  0.0544899 , -0.06845541,  0.03424844,\n",
      "          -0.0696881 ,  0.08034517, -0.12978578, -0.05271877,\n",
      "          -0.01421937,  0.05641118, -0.06887304,  0.09903769]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00750405, -0.10019352, -0.0126614 ,  0.08621265,\n",
      "          -0.05683456, -0.09543885,  0.04896009,  0.05265257,\n",
      "           0.08727549, -0.13413891, -0.05991025, -0.13371213,\n",
      "           0.09343459, -0.04348569, -0.0238576 , -0.04538105,\n",
      "           0.03524897,  0.03026475,  0.13681965,  0.04918934,\n",
      "           0.01171739,  0.11533745, -0.08679324,  0.01261622,\n",
      "          -0.10204272,  0.02672546,  0.0358444 ,  0.02781415,\n",
      "          -0.0860892 ,  0.11177157, -0.09974393,  0.01845145]],\n",
      "\n",
      "        [[ 0.05124688,  0.00093608,  0.00947954,  0.10816844,\n",
      "           0.08796331,  0.01764002,  0.03905615, -0.02660536,\n",
      "          -0.00842361,  0.08685109, -0.13179259, -0.08653279,\n",
      "          -0.03226783, -0.10771912, -0.08787015,  0.01663363,\n",
      "          -0.10911243,  0.09174141,  0.07870342, -0.10873347,\n",
      "           0.03275354,  0.08471201, -0.03824247,  0.01548618,\n",
      "          -0.03584078, -0.04686122,  0.03653994,  0.1028575 ,\n",
      "           0.09629688, -0.00848816, -0.1347335 , -0.014823  ]],\n",
      "\n",
      "        [[-0.1304314 ,  0.03416277, -0.05831673, -0.13807076,\n",
      "          -0.02208526, -0.02802408,  0.0309834 , -0.0559661 ,\n",
      "          -0.02306115,  0.0451332 ,  0.05513921,  0.04701729,\n",
      "           0.09908985,  0.1204531 , -0.02405744, -0.00731181,\n",
      "           0.00646994,  0.08913201,  0.01276706,  0.01613162,\n",
      "          -0.1275776 ,  0.03151594, -0.05374435, -0.03155698,\n",
      "          -0.04409929, -0.03488576, -0.06664979, -0.05472372,\n",
      "          -0.11843213,  0.10147375, -0.00153869,  0.02737057]]],\n",
      "\n",
      "\n",
      "       [[[ 0.12650119, -0.12126887,  0.09409055,  0.01081894,\n",
      "           0.09446979, -0.01812384, -0.0221181 , -0.06266197,\n",
      "           0.03641917, -0.02692603,  0.09977843, -0.1086555 ,\n",
      "          -0.11366527,  0.12796928,  0.03664641,  0.13977353,\n",
      "          -0.06374345,  0.01916878,  0.02550253,  0.1245638 ,\n",
      "          -0.067582  ,  0.12877075,  0.12380616,  0.10839938,\n",
      "          -0.0083186 ,  0.02160792,  0.1269709 ,  0.10085768,\n",
      "          -0.08794965,  0.12750171, -0.01594053,  0.12019177]],\n",
      "\n",
      "        [[ 0.00615689,  0.13431387,  0.11800145,  0.03912823,\n",
      "           0.06698363, -0.0914435 ,  0.13553347,  0.0101255 ,\n",
      "           0.02374846, -0.04097766, -0.1243943 , -0.00615008,\n",
      "          -0.0954413 ,  0.10262324,  0.05347334, -0.04437409,\n",
      "           0.05664527, -0.08460443, -0.03994301, -0.0175591 ,\n",
      "           0.01885545,  0.08147506,  0.00392616, -0.02890591,\n",
      "          -0.08065736,  0.11527212, -0.04816893, -0.02191409,\n",
      "           0.01475546,  0.03791749,  0.02272299, -0.04966515]],\n",
      "\n",
      "        [[-0.03233968, -0.10222964,  0.09561639,  0.06617245,\n",
      "          -0.07959608,  0.04590492,  0.01203288, -0.08150299,\n",
      "          -0.00724532,  0.00197272, -0.06380025, -0.11382809,\n",
      "           0.0102741 , -0.13157059, -0.04793625,  0.0118075 ,\n",
      "          -0.05023941, -0.12368619, -0.01080881,  0.04369268,\n",
      "          -0.13063058,  0.06119908, -0.00326176, -0.10086483,\n",
      "           0.05759673,  0.06745011,  0.05915046, -0.1124215 ,\n",
      "          -0.0332076 , -0.08952931, -0.01195617, -0.06157506]]]],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'conv2d_13/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\n",
      "array([[[[-1.78318843e-02, -2.04213634e-02,  1.95693746e-02, ...,\n",
      "           2.71690264e-02,  1.87961087e-02, -5.90662770e-02],\n",
      "         [-2.29034051e-02,  6.64038286e-02, -4.21044827e-02, ...,\n",
      "           5.13872132e-02, -1.25909671e-02, -1.32799968e-02],\n",
      "         [ 4.63707820e-02,  1.27364993e-02,  9.00506973e-03, ...,\n",
      "           3.73071656e-02,  5.58436140e-02, -4.22942638e-02],\n",
      "         ...,\n",
      "         [ 4.08224091e-02, -2.30396390e-02,  1.69335231e-02, ...,\n",
      "          -5.32491021e-02, -4.44542579e-02,  2.31099501e-02],\n",
      "         [ 1.28235593e-02,  2.14972869e-02, -6.74085617e-02, ...,\n",
      "          -4.51027751e-02, -3.63055095e-02, -4.07732949e-02],\n",
      "         [-1.28591657e-02,  7.79304281e-02,  8.06074962e-02, ...,\n",
      "          -2.60317326e-02,  8.21741894e-02, -7.00247288e-02]],\n",
      "\n",
      "        [[ 7.10947737e-02,  1.46728754e-03,  7.53796175e-02, ...,\n",
      "          -6.62015527e-02,  4.90227565e-02,  6.60758689e-02],\n",
      "         [-1.04347244e-02, -2.47265920e-02,  5.63367382e-02, ...,\n",
      "          -3.11971903e-02,  5.94362244e-02,  5.54029718e-02],\n",
      "         [ 6.01500943e-02, -5.79284839e-02,  3.76515165e-02, ...,\n",
      "          -1.86156854e-02,  1.32765621e-03,  8.22631493e-02],\n",
      "         ...,\n",
      "         [-1.12839118e-02,  3.22903022e-02,  4.97834161e-02, ...,\n",
      "          -3.44179682e-02,  3.10229287e-02,  1.96273699e-02],\n",
      "         [-1.70006603e-03,  5.63827232e-02, -5.00390343e-02, ...,\n",
      "           4.43716720e-02,  7.48193637e-02, -5.32312207e-02],\n",
      "         [ 6.64151087e-02, -7.56977424e-02, -1.97031274e-02, ...,\n",
      "          -9.59549099e-03, -4.13929820e-02, -7.19938502e-02]],\n",
      "\n",
      "        [[ 1.75588354e-02, -7.37775788e-02, -5.44046573e-02, ...,\n",
      "           3.20050120e-02, -3.53869013e-02, -1.44398436e-02],\n",
      "         [ 2.55561471e-02,  1.14663616e-02, -7.53616318e-02, ...,\n",
      "          -2.11738348e-02,  1.95544139e-02, -7.20544681e-02],\n",
      "         [-4.65335250e-02,  3.16524729e-02, -6.56603575e-02, ...,\n",
      "           5.47721460e-02, -1.05227605e-02, -7.88283795e-02],\n",
      "         ...,\n",
      "         [-4.75405082e-02,  2.42019519e-02, -2.41828561e-02, ...,\n",
      "          -4.57624793e-02, -2.57939920e-02,  4.37437370e-02],\n",
      "         [-7.35239834e-02, -3.81778888e-02,  2.02563182e-02, ...,\n",
      "          -7.24119172e-02, -6.54515475e-02, -4.58147153e-02],\n",
      "         [ 4.56983820e-02, -4.05513458e-02,  6.36339560e-02, ...,\n",
      "           8.15945491e-02,  5.77572808e-02, -5.26308231e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 4.42018360e-03, -4.91238646e-02,  1.28487945e-02, ...,\n",
      "          -6.34147972e-02,  2.90439725e-02,  7.25871548e-02],\n",
      "         [-2.75474191e-02, -4.84002456e-02,  2.26718560e-02, ...,\n",
      "          -4.24789190e-02,  5.73425665e-02, -2.23286375e-02],\n",
      "         [ 8.30367580e-02,  1.68562904e-02, -9.88277048e-03, ...,\n",
      "           5.45412377e-02, -1.71276182e-03,  7.05359951e-02],\n",
      "         ...,\n",
      "         [ 3.50592956e-02,  5.99133447e-02,  6.42156601e-03, ...,\n",
      "          -6.37646914e-02,  3.04493681e-02, -8.26142430e-02],\n",
      "         [-6.60938025e-03, -2.03832984e-02,  7.23874569e-03, ...,\n",
      "          -2.17184424e-02, -7.31257424e-02, -7.14501962e-02],\n",
      "         [ 8.03137496e-02,  1.01220608e-02, -6.45253062e-02, ...,\n",
      "          -1.00488067e-02,  4.55032066e-02,  7.75298849e-02]],\n",
      "\n",
      "        [[ 4.72149327e-02, -6.51463270e-02,  8.04309472e-02, ...,\n",
      "           7.60937557e-02,  3.71642485e-02, -6.58446550e-02],\n",
      "         [ 4.49763611e-02, -2.66915560e-03,  7.91390762e-02, ...,\n",
      "          -1.38580799e-03, -3.66374254e-02,  6.84876069e-02],\n",
      "         [ 4.47022915e-03,  5.49647287e-02,  2.10749507e-02, ...,\n",
      "          -5.71369156e-02,  6.00609854e-02,  1.36907324e-02],\n",
      "         ...,\n",
      "         [-6.40717372e-02,  2.47793198e-02,  6.81941286e-02, ...,\n",
      "           8.30557421e-02, -7.24527985e-03, -2.93367133e-02],\n",
      "         [ 1.42929778e-02, -5.76951131e-02, -3.35045271e-02, ...,\n",
      "          -1.43048912e-03, -4.24780697e-03, -9.92983580e-03],\n",
      "         [-4.94848490e-02,  4.34696674e-03,  6.56416491e-02, ...,\n",
      "           9.70993191e-03, -2.29157805e-02,  8.36833566e-03]],\n",
      "\n",
      "        [[-6.59198388e-02, -4.95950803e-02, -1.25498548e-02, ...,\n",
      "          -5.20254001e-02, -7.94281960e-02,  1.79600492e-02],\n",
      "         [ 8.15582946e-02,  6.48746863e-02, -1.51658058e-03, ...,\n",
      "           2.95298472e-02, -3.24835777e-02,  9.66242701e-03],\n",
      "         [ 7.43484274e-02,  3.13391313e-02,  5.83746061e-02, ...,\n",
      "          -4.22874317e-02, -3.28997187e-02,  1.45396814e-02],\n",
      "         ...,\n",
      "         [ 3.96500453e-02,  2.45892406e-02,  6.19783625e-02, ...,\n",
      "           6.11116514e-02, -2.36696601e-02, -4.08280306e-02],\n",
      "         [-4.27663140e-02,  5.53628430e-02, -3.32371220e-02, ...,\n",
      "           3.40530649e-02,  4.78207693e-02, -3.75200920e-02],\n",
      "         [ 6.81064203e-02,  2.14566216e-02, -1.37587786e-02, ...,\n",
      "           3.82385403e-03,  3.17711830e-02,  6.07161000e-02]]],\n",
      "\n",
      "\n",
      "       [[[-4.12425809e-02,  4.41232100e-02,  7.37433061e-02, ...,\n",
      "           1.11795664e-02, -4.89567742e-02, -1.57326683e-02],\n",
      "         [-3.49078774e-02, -5.97126484e-02, -7.19682127e-03, ...,\n",
      "          -7.15873390e-03, -6.98484629e-02, -1.19420290e-02],\n",
      "         [ 8.19053501e-03,  1.69639587e-02, -5.79674654e-02, ...,\n",
      "          -5.22532277e-02, -5.32593131e-02,  7.00249895e-02],\n",
      "         ...,\n",
      "         [-6.00427017e-02,  7.58921281e-02,  8.13661888e-02, ...,\n",
      "           4.70266491e-03,  2.63035297e-03,  2.11154819e-02],\n",
      "         [-1.86157227e-03, -6.98921829e-03, -3.98377329e-03, ...,\n",
      "           7.12837651e-02, -6.45180345e-02, -1.21824965e-02],\n",
      "         [ 4.55804840e-02,  6.50807098e-02, -7.38260970e-02, ...,\n",
      "           4.61449698e-02,  2.48125568e-02,  4.24343571e-02]],\n",
      "\n",
      "        [[-7.93826208e-02,  5.87900504e-02, -8.01806897e-02, ...,\n",
      "          -3.69680934e-02,  1.52925625e-02,  6.60406575e-02],\n",
      "         [ 2.34090462e-02, -5.38234711e-02,  4.89237681e-02, ...,\n",
      "           2.63717547e-02,  2.43991613e-03,  5.78076318e-02],\n",
      "         [ 7.19944462e-02, -3.33509594e-03,  2.21476182e-02, ...,\n",
      "          -7.42052048e-02,  6.23135939e-02,  3.31511348e-03],\n",
      "         ...,\n",
      "         [-7.80214071e-02, -4.60848212e-02,  4.42106202e-02, ...,\n",
      "           6.09363988e-02,  7.43801817e-02, -6.10441975e-02],\n",
      "         [-8.24196339e-02,  2.08356157e-02,  4.78043929e-02, ...,\n",
      "          -1.66428909e-02, -7.55216479e-02,  1.97380781e-03],\n",
      "         [ 6.52085766e-02, -9.34424251e-03,  6.07122257e-02, ...,\n",
      "          -7.99749345e-02, -7.72086531e-03, -8.03784281e-03]],\n",
      "\n",
      "        [[-2.44333372e-02, -5.57595119e-02,  5.56816682e-02, ...,\n",
      "          -2.27915458e-02,  2.36911178e-02, -2.40858011e-02],\n",
      "         [ 3.56793180e-02, -2.38840394e-02,  1.01930127e-02, ...,\n",
      "           7.59819821e-02,  3.39500308e-02, -5.71857095e-02],\n",
      "         [ 7.67764077e-02, -1.42216906e-02,  6.59413412e-02, ...,\n",
      "           4.22701910e-02,  7.41695389e-02,  7.21447244e-02],\n",
      "         ...,\n",
      "         [ 2.94500589e-03,  1.50628686e-02,  7.78033212e-02, ...,\n",
      "          -3.20363864e-02,  5.71331605e-02,  7.16075301e-05],\n",
      "         [ 2.48676538e-02,  6.92893341e-02,  2.18080655e-02, ...,\n",
      "           7.77475312e-02, -4.01927046e-02,  3.44016775e-02],\n",
      "         [ 1.56389475e-02, -2.94526666e-03, -3.46593075e-02, ...,\n",
      "          -5.55307083e-02,  5.06049395e-03, -6.37955517e-02]]]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].kernel)\n",
    "print(model.layers[2].kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "* batch_size:\n",
    "* epochs: number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 58s 122ms/step - loss: 0.2712 - accuracy: 0.9255 - val_loss: 10.0669 - val_accuracy: 0.9777\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.0732 - accuracy: 0.9780 - val_loss: 5.4060 - val_accuracy: 0.9849\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.0537 - accuracy: 0.9840 - val_loss: 7.1290 - val_accuracy: 0.9826\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 48s 103ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 5.9989 - val_accuracy: 0.9859\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0371 - accuracy: 0.9883 - val_loss: 6.8260 - val_accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.0316 - accuracy: 0.9901 - val_loss: 7.4118 - val_accuracy: 0.9867\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 5.9236 - val_accuracy: 0.9887\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 7.1337 - val_accuracy: 0.9882\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 50s 108ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 6.5046 - val_accuracy: 0.9875\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 49s 105ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 9.1546 - val_accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f875c1d0a50>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=128, epochs=10, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 9.1546 - accuracy: 0.9868 - 2s/epoch - 6ms/step\n",
      "Test accuracy: 0.9868000149726868\n",
      "Test loss: 9.15458869934082\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test,verbose=2)\n",
    "print('Test accuracy:',test_acc)\n",
    "print('Test loss:',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

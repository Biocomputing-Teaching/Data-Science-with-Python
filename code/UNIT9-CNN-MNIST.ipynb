{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT 9. Convolutional Neural Networks on the MNIST dataset\n",
    "\n",
    "This Unit includes an implementation of a CNN to calssify digits from the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database). Code adapted from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":style: unsrt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we start by importing:\n",
    "* the dataset *MNIST*\n",
    "* the **[Sequential](https://keras.io/guides/sequential_model/)** function\n",
    "* the differential layers:\n",
    "  * **[Conv2D](https://towardsdatascience.com/conv2d-to-finally-understand-what-happens-in-the-forward-pass-1bbaafb0b148)**: creates the convolutional kernel to produce a set of output features\n",
    "  * **[MaxPooling2D](https://deepai.org/machine-learning-glossary-and-terms/max-pooling)**: downsamples the input by taking the maximum value of the kernel, reducing the dimensionality of the model\n",
    "  * **Flatten**: flattens the input tensor into a one dimensional vector. Useful when transitioning from a CNN to a fully connected CNN\n",
    "  * **Dense**: standard fully connected NN layer. Each neuron in the layer is connected to all neurons in the previous layer. \n",
    "* **to_categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us now load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us display a collection of sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[3],cmap='gray')\n",
    "plt.show()\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(X_train[i],cmap='gray')\n",
    "    plt.title(y_train[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "* Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-normalization data: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "post-normalization data: [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333336\n",
      "  0.6862745  0.10196079 0.6509804  1.         0.96862745 0.49803922\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
      "  0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "  0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19215687 0.93333334 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.9843137\n",
      "  0.3647059  0.32156864 0.32156864 0.21960784 0.15294118 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07058824 0.85882354 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.7764706  0.7137255  0.96862745 0.94509804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
      "  0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05490196 0.00392157 0.6039216\n",
      "  0.99215686 0.3529412  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54509807\n",
      "  0.99215686 0.74509805 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04313726\n",
      "  0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13725491 0.94509804 0.88235295 0.627451   0.42352942 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31764707 0.9411765  0.99215686 0.99215686 0.46666667\n",
      "  0.09803922 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      "  0.5882353  0.10588235 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0627451  0.3647059  0.9882353\n",
      "  0.99215686 0.73333335 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.9764706\n",
      "  0.99215686 0.9764706  0.2509804  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
      "  0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15294118 0.5803922  0.8980392  0.99215686 0.99215686 0.99215686\n",
      "  0.98039216 0.7137255  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09411765 0.44705883\n",
      "  0.8666667  0.99215686 0.99215686 0.99215686 0.99215686 0.7882353\n",
      "  0.30588236 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07058824 0.67058825 0.85882354 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.7647059  0.3137255  0.03529412 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21568628 0.6745098\n",
      "  0.8862745  0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "  0.52156866 0.04313726 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53333336 0.99215686\n",
      "  0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('pre-normalization data:',X_train[0])\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_text = X_test.astype('float32')/255\n",
    "print('post-normalization data:',X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reshape the dataset to be 4D\n",
    "  * `batch_size`: the number of training examples processed\n",
    "  * `height`/`width`: height/width of each input image in pixels\n",
    "  * `channels`: number of color channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.expand_dims(X_train,axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [One hot encoding](https://blog.gopenai.com/one-hot-encoding-for-ml-with-tensorflow-and-keras-50f67ca9681a) using the `to_categorial` function. It converts the data into an integer. In this particular case, the best choice for this dataset would be to apply *sparse categorical crossentropy loss*— for the simple reason that we don’t have to apply one-hot encoding if we use that loss function. However, for the sake of training, we will apply here one hot encoding to use *categorical crossentropy loss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "[7 2 1 ... 4 5 6]\n",
      "(10000, 10)\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_test)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print(y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model architecture\n",
    "\n",
    "* 4 layers (2 [convolutional](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) and 2 Maxpooling)\n",
    "* 1 flattening layer\n",
    "* 1 fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# first layer with 32 filters and a filter size of (3,3)\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=X_train.shape[1:]))\n",
    "# we reduce the size to half with the MaxPooling layer\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "# the third layer uses 64 filters\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "# convert the 2D map to a 1D vector\n",
    "model.add(Flatten())\n",
    "# fully connected layer with 10 output units, as the categories we have. Linear transformation followed by a softmax to finally select one category\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model. We will use the Adam optimizer (Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us have a look at the different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d_10/kernel:0' shape=(3, 3, 1, 32) dtype=float32, numpy=\n",
      "array([[[[-0.09895009,  0.12586771,  0.0380891 ,  0.01202892,\n",
      "           0.12914778, -0.10574912, -0.08778048, -0.12628773,\n",
      "          -0.05951766,  0.08407287, -0.0634855 , -0.1352705 ,\n",
      "          -0.01566178, -0.05151564, -0.13294259,  0.03796636,\n",
      "          -0.12008007,  0.1365638 , -0.05711549,  0.05514371,\n",
      "          -0.11983944, -0.0225997 ,  0.10617192, -0.02577193,\n",
      "           0.10914858,  0.03174204,  0.04436368,  0.10029989,\n",
      "          -0.00344543, -0.12739943, -0.01344968, -0.13784151]],\n",
      "\n",
      "        [[ 0.1044555 ,  0.01781902,  0.02199383, -0.12023012,\n",
      "          -0.04995723, -0.00367288, -0.06849337,  0.01848941,\n",
      "           0.01262161, -0.1155962 ,  0.08964667,  0.05011003,\n",
      "           0.10364786,  0.12845232, -0.00018822, -0.10542786,\n",
      "          -0.03088594, -0.01458508,  0.05325902, -0.0919062 ,\n",
      "           0.08324015, -0.05581184,  0.00665845,  0.06352873,\n",
      "          -0.12388057,  0.05809985, -0.06612539, -0.12414286,\n",
      "           0.14141409, -0.00494799, -0.12790981, -0.03598612]],\n",
      "\n",
      "        [[ 0.04581521, -0.07237835,  0.122537  ,  0.07803324,\n",
      "          -0.03324141,  0.10070105, -0.12261034, -0.02228971,\n",
      "          -0.07425734, -0.08277173,  0.10691352, -0.01564278,\n",
      "           0.07159978,  0.02291042, -0.10113938, -0.09534051,\n",
      "           0.11786063, -0.04811325,  0.04364344,  0.06490077,\n",
      "          -0.13015525,  0.05736391, -0.12330431, -0.03000768,\n",
      "          -0.04355045, -0.1410942 ,  0.02121533,  0.01902649,\n",
      "           0.12632544,  0.12829109, -0.01026858,  0.03481422]]],\n",
      "\n",
      "\n",
      "       [[[-0.0494396 , -0.0752219 , -0.06591143, -0.10917176,\n",
      "           0.10545084,  0.01733789, -0.13710317,  0.1111335 ,\n",
      "           0.10135433,  0.1318127 , -0.12391039, -0.07948185,\n",
      "          -0.08952697,  0.07306843,  0.00848579, -0.13669568,\n",
      "           0.13269727, -0.07780344,  0.02013081, -0.01434167,\n",
      "          -0.12951505,  0.00056501,  0.09779501,  0.09877306,\n",
      "           0.04442902,  0.13052408, -0.10644113, -0.07167461,\n",
      "           0.03224258, -0.04352717, -0.11932113, -0.12933598]],\n",
      "\n",
      "        [[ 0.13882212, -0.07661294,  0.00019407, -0.13557984,\n",
      "           0.13860996,  0.08124253, -0.05829108,  0.02636787,\n",
      "          -0.1311023 , -0.07926433, -0.05270837, -0.04864335,\n",
      "          -0.0833018 , -0.08937486, -0.01859646, -0.13864338,\n",
      "          -0.03041233, -0.13597469,  0.08232138, -0.05071139,\n",
      "           0.01489955, -0.04154066, -0.09169257,  0.00554638,\n",
      "           0.08752179, -0.04777888,  0.06193843,  0.06657389,\n",
      "          -0.06164562,  0.05469333, -0.0379913 , -0.09331889]],\n",
      "\n",
      "        [[-0.13945228,  0.06250486,  0.01879981,  0.10530882,\n",
      "          -0.08408684,  0.12102322, -0.0031729 ,  0.06922194,\n",
      "          -0.14191921, -0.08229256,  0.08824918,  0.05468214,\n",
      "          -0.13850729,  0.04427947, -0.04206511,  0.1289305 ,\n",
      "          -0.1413071 ,  0.01568568,  0.03731698, -0.0540168 ,\n",
      "           0.1370352 ,  0.01460253,  0.00485477,  0.10106911,\n",
      "           0.03995131, -0.03578801,  0.06230421,  0.12457784,\n",
      "          -0.13088125, -0.10117425, -0.03420562, -0.11208107]]],\n",
      "\n",
      "\n",
      "       [[[ 0.07064965,  0.14065818, -0.08396657,  0.12251942,\n",
      "          -0.02667737,  0.0331874 , -0.03735703, -0.09184226,\n",
      "          -0.06954954,  0.02473074,  0.12200554,  0.07250912,\n",
      "           0.0499797 ,  0.09096909, -0.08950579,  0.01585981,\n",
      "          -0.11281388, -0.00487344,  0.06820621, -0.00553454,\n",
      "           0.10003093,  0.01298146,  0.06299053,  0.02478582,\n",
      "           0.10044968,  0.02354845, -0.13075247, -0.10080972,\n",
      "           0.11604194, -0.12947954, -0.01883679, -0.11579908]],\n",
      "\n",
      "        [[ 0.13728805, -0.04272956,  0.14167635,  0.12383692,\n",
      "          -0.01789533,  0.05001877, -0.1414604 ,  0.08378917,\n",
      "          -0.0806348 , -0.12545836,  0.00213839, -0.10381106,\n",
      "          -0.04458683,  0.10421723,  0.02246086, -0.10079668,\n",
      "          -0.01043259,  0.06046413,  0.13578625, -0.08540718,\n",
      "          -0.09007822,  0.03847091, -0.127811  ,  0.05932152,\n",
      "          -0.02629966,  0.11671863, -0.03295324, -0.06803745,\n",
      "          -0.07679966,  0.13353588, -0.0094661 ,  0.07449451]],\n",
      "\n",
      "        [[-0.06944998, -0.00788565, -0.1298912 ,  0.06547743,\n",
      "           0.01294161,  0.00751157, -0.01091671, -0.11712811,\n",
      "           0.14066078, -0.11277209,  0.07537003, -0.10142763,\n",
      "          -0.14138626,  0.13648792, -0.12313952, -0.02407242,\n",
      "          -0.03571892, -0.12671266, -0.08116221, -0.1243188 ,\n",
      "           0.0781642 ,  0.06915593, -0.04189218, -0.14081404,\n",
      "          -0.01319095, -0.07411169,  0.11723723,  0.09031115,\n",
      "          -0.08744581,  0.00793615,  0.07459949,  0.12490498]]]],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'conv2d_11/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\n",
      "array([[[[-4.16762643e-02,  2.10985169e-02, -2.89490819e-02, ...,\n",
      "           1.03016123e-02,  4.83668819e-02,  1.39474869e-04],\n",
      "         [ 4.41271290e-02, -7.52920732e-02,  6.50372282e-02, ...,\n",
      "           8.27679858e-02, -3.65404487e-02,  1.91412568e-02],\n",
      "         [-2.65458450e-02,  2.25330964e-02,  1.06100067e-02, ...,\n",
      "           4.73350063e-02, -7.34127164e-02,  3.08410525e-02],\n",
      "         ...,\n",
      "         [-3.32056694e-02, -4.15606312e-02, -5.52277975e-02, ...,\n",
      "           3.22143435e-02, -3.41898799e-02, -1.25345960e-02],\n",
      "         [-6.04166016e-02,  2.58575678e-02,  1.09168142e-03, ...,\n",
      "          -3.51947173e-02,  5.89659885e-02, -7.12451786e-02],\n",
      "         [-6.65354729e-02, -6.62174076e-03,  4.40722927e-02, ...,\n",
      "          -6.12492189e-02, -2.03183070e-02, -1.42697468e-02]],\n",
      "\n",
      "        [[-2.31087208e-04,  7.11072311e-02,  7.63563290e-02, ...,\n",
      "          -7.98781961e-03, -6.51046261e-02, -4.71491441e-02],\n",
      "         [ 7.72343054e-02,  7.22528920e-02,  8.53121281e-03, ...,\n",
      "           7.19631985e-02, -1.46481618e-02,  7.58097842e-02],\n",
      "         [ 4.67678085e-02, -5.62005453e-02,  1.32442713e-02, ...,\n",
      "          -2.70291790e-02, -3.70434336e-02,  5.60675487e-02],\n",
      "         ...,\n",
      "         [ 6.14380315e-02, -7.40995854e-02,  2.82161832e-02, ...,\n",
      "          -6.61671162e-04,  6.57533184e-02, -5.38772568e-02],\n",
      "         [-7.03414306e-02,  6.55097142e-02,  1.82700530e-02, ...,\n",
      "           3.54517326e-02, -6.76787943e-02, -7.46910572e-02],\n",
      "         [-7.68659115e-02,  7.40897134e-02,  1.40815377e-02, ...,\n",
      "          -7.96452761e-02, -3.69399786e-02, -6.86122179e-02]],\n",
      "\n",
      "        [[ 3.70146856e-02,  4.47841063e-02, -6.71734437e-02, ...,\n",
      "          -1.65015087e-02,  1.31024495e-02,  4.54078987e-02],\n",
      "         [ 1.65920258e-02, -8.18148851e-02,  1.98975205e-02, ...,\n",
      "           7.17238337e-03,  4.59804013e-02,  5.58696762e-02],\n",
      "         [-6.84202537e-02,  2.65934467e-02, -5.39822988e-02, ...,\n",
      "           2.89379358e-02, -5.39753847e-02,  5.48177585e-02],\n",
      "         ...,\n",
      "         [ 7.61243477e-02, -5.46800308e-02, -4.19492945e-02, ...,\n",
      "          -8.17145109e-02, -7.78471455e-02,  4.90439907e-02],\n",
      "         [-7.01976418e-02,  2.66548619e-02, -4.89623360e-02, ...,\n",
      "           3.99484858e-02, -8.06613564e-02,  1.85202360e-02],\n",
      "         [ 1.38485432e-02,  4.88412157e-02,  8.25715438e-02, ...,\n",
      "          -5.65263443e-02,  8.02947953e-02, -6.46613538e-04]]],\n",
      "\n",
      "\n",
      "       [[[ 3.26135755e-02, -2.66078934e-02, -2.66960077e-02, ...,\n",
      "           7.55619183e-02,  4.90284339e-02,  6.32336959e-02],\n",
      "         [-2.95128226e-02,  1.33370161e-02,  1.42486319e-02, ...,\n",
      "          -7.07011074e-02, -6.44686073e-02, -5.09545021e-02],\n",
      "         [ 2.42300853e-02,  2.62086168e-02,  7.12150708e-02, ...,\n",
      "          -1.66959167e-02, -5.02682552e-02,  7.77819008e-03],\n",
      "         ...,\n",
      "         [-8.28705877e-02,  3.92897502e-02,  6.60049990e-02, ...,\n",
      "           7.81886056e-02,  3.69054452e-02, -4.68926430e-02],\n",
      "         [ 1.87538564e-04,  3.84567603e-02,  7.54197910e-02, ...,\n",
      "          -5.97773790e-02,  3.11388820e-03,  5.69864288e-02],\n",
      "         [ 5.49652949e-02, -2.97829732e-02,  3.16342339e-02, ...,\n",
      "           8.13803822e-03,  1.45540237e-02, -3.50398421e-02]],\n",
      "\n",
      "        [[ 2.92416662e-03,  5.14582023e-02, -1.85672268e-02, ...,\n",
      "          -4.67610359e-03, -3.75786424e-02,  2.46220455e-02],\n",
      "         [ 7.61094168e-02, -1.08678117e-02, -7.71685690e-02, ...,\n",
      "          -3.69532108e-02,  3.05473804e-03,  5.49299493e-02],\n",
      "         [-2.28015333e-03, -6.61610961e-02, -1.46253332e-02, ...,\n",
      "           1.69435516e-02, -1.72121301e-02, -7.32547045e-03],\n",
      "         ...,\n",
      "         [ 5.72304800e-02,  6.69902936e-02, -2.60406360e-02, ...,\n",
      "          -3.53982262e-02,  8.32801238e-02, -5.90230636e-02],\n",
      "         [-6.47376403e-02,  5.87680191e-03, -7.04736933e-02, ...,\n",
      "           4.07241285e-04, -4.47552204e-02,  5.56218401e-02],\n",
      "         [ 4.05249372e-02,  4.76715639e-02, -3.27413306e-02, ...,\n",
      "           1.70387998e-02,  1.27893686e-03, -6.81309924e-02]],\n",
      "\n",
      "        [[-2.63661742e-02,  7.17655495e-02, -1.13498569e-02, ...,\n",
      "           3.80775109e-02,  1.46398172e-02,  2.85312906e-02],\n",
      "         [ 5.80138788e-02,  3.02547440e-02, -4.68079261e-02, ...,\n",
      "          -1.04384199e-02,  2.25967541e-02,  2.90893093e-02],\n",
      "         [ 8.26673880e-02,  2.36128569e-02, -3.90981846e-02, ...,\n",
      "           2.78111547e-03,  5.30982390e-02, -5.02269268e-02],\n",
      "         ...,\n",
      "         [-4.93777394e-02, -3.56587023e-03, -5.62772751e-02, ...,\n",
      "          -5.75698838e-02, -7.85811767e-02, -7.87101239e-02],\n",
      "         [-2.23819241e-02,  7.09790066e-02, -2.27273330e-02, ...,\n",
      "           5.28835431e-02, -2.71080360e-02, -2.66892724e-02],\n",
      "         [-2.86516175e-02, -7.18727708e-02,  5.88801876e-02, ...,\n",
      "          -7.55929351e-02,  8.14667419e-02, -6.93788752e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 8.86026770e-03,  3.95695344e-02, -6.90134764e-02, ...,\n",
      "          -7.96072111e-02, -5.41725568e-02,  5.37660196e-02],\n",
      "         [ 1.93216428e-02, -8.55533034e-03,  1.47373453e-02, ...,\n",
      "           7.59888664e-02, -7.56972879e-02, -3.36963534e-02],\n",
      "         [ 7.85459504e-02, -5.45250587e-02, -2.90186405e-02, ...,\n",
      "           8.25486407e-02, -2.61187553e-02,  4.73964885e-02],\n",
      "         ...,\n",
      "         [ 1.47990361e-02,  7.51151890e-03,  1.48547664e-02, ...,\n",
      "          -1.07978806e-02,  6.46033362e-02,  5.78679219e-02],\n",
      "         [ 7.81540498e-02,  4.83069494e-02,  4.07679901e-02, ...,\n",
      "          -7.86303729e-02, -2.08194852e-02,  2.10275427e-02],\n",
      "         [-1.80603042e-02,  1.79257244e-03, -6.85494989e-02, ...,\n",
      "          -5.71457744e-02,  2.97464356e-02,  4.89480123e-02]],\n",
      "\n",
      "        [[ 7.78546557e-02, -3.47024016e-02, -2.43923068e-02, ...,\n",
      "           1.98934078e-02, -1.79194435e-02, -2.85144262e-02],\n",
      "         [ 2.60332972e-03,  4.93651256e-02,  5.70007041e-02, ...,\n",
      "           4.59924340e-05,  1.55155659e-02,  7.27480873e-02],\n",
      "         [ 1.06346235e-02, -9.63427126e-04,  6.95583001e-02, ...,\n",
      "          -7.35906363e-02, -4.90204692e-02,  5.23250327e-02],\n",
      "         ...,\n",
      "         [ 6.92921057e-02,  2.42015347e-02,  3.66410241e-02, ...,\n",
      "          -4.74430919e-02, -6.35430440e-02,  5.97349182e-02],\n",
      "         [ 7.97136053e-02, -5.20447306e-02,  7.19194487e-02, ...,\n",
      "          -1.57673359e-02, -6.62750453e-02,  4.29884568e-02],\n",
      "         [-3.37708220e-02,  4.36807498e-02, -3.64715271e-02, ...,\n",
      "           6.72193244e-02, -3.14079225e-04, -7.27692246e-02]],\n",
      "\n",
      "        [[-7.90413469e-03,  1.48657709e-03, -5.78440428e-02, ...,\n",
      "          -4.74560857e-02, -1.54495239e-03, -3.04916725e-02],\n",
      "         [-7.58713111e-02, -5.10669574e-02, -8.31649154e-02, ...,\n",
      "           6.58161417e-02, -2.86743641e-02,  3.62172946e-02],\n",
      "         [ 1.12231597e-02, -4.97907400e-02, -7.67799243e-02, ...,\n",
      "          -3.32058072e-02, -2.84564905e-02,  4.24181446e-02],\n",
      "         ...,\n",
      "         [ 7.07747117e-02,  5.66356853e-02,  1.64313316e-02, ...,\n",
      "          -3.61721516e-02, -3.00713405e-02,  4.91903201e-02],\n",
      "         [-2.39445381e-02,  1.44480094e-02,  5.45903295e-03, ...,\n",
      "           4.34828475e-02,  7.90765658e-02,  3.71918306e-02],\n",
      "         [-8.09820294e-02,  7.39369169e-02, -3.54158878e-02, ...,\n",
      "           7.00723752e-02, -4.15962934e-02,  1.97359100e-02]]]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].kernel)\n",
    "print(model.layers[2].kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "* batch_size:\n",
    "* epochs: number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.9196"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=128, epochs=10, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 8.3964 - accuracy: 0.9877 - 1s/epoch - 4ms/step\n",
      "Test accuracy: 0.9876999855041504\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test,verbose=2)\n",
    "print('Test accuracy:',test_acc)\n",
    "print('Test loss:',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

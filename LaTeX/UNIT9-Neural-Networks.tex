%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12) 
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass{beamer}

\input{../tools/common_beamer.tex}
\graphicspath{{../figures}}

%----------------------------------------------------------------------------------------
%	 TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Neural Networks]{Neural Networks} % The short title appears at the bottom of every slide, the full title is only on the title page

\author{Jordi Villà i Freixa} % Your name
\institute[FCTE] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
Universitat de Vic - Universitat Central de Catalunya \\
Study Abroad\\ % Your institution for the title page
\medskip
\textit{jordi.villa@uvic.cat} % Your email address
}
%\date{\today} % Date, can be changed to a custom date
\date{course 2023-2024}
\logo{\includegraphics[width=.1\textwidth]{FCTE}}
\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

\begin{frame}
\frametitle{Index} % Table of contents slide, comment this block out to remove it
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

%\subsection{Subsection Example} % A subsection can be created just before a set of slides with a common theme to further break down your presentation into chunks

\begin{frame}{What to expect?}
  In this session we will discuss:
  \begin{itemize}
    \item Neural networks
    \item Gradient Descent
    \item Backpropagation
    \item Network training
    \item Convolutional Neural Networks
  \end{itemize}
\end{frame}

\section{Introduction to NN}

\begin{frame}{Evolution of AI}
    \begin{figure}
        \includegraphics[width=0.7\linewidth]{MLDLevol}
        \caption{Evolution of AI, ML and DL. Source \href{https://blog.bismart.com/diferencia-machine-learning-deep-learning}{BISMART}. Check also this \href{https://www.3blue1brown.com/topics/neural-networks}{3blue1brown set of videos}.}
        \label{Fig:MLDLevol}
    \end{figure}
\end{frame}

\begin{frame}{Supervised ML}
    \begin{figure}
        \includegraphics[width=0.9\linewidth]{ML}
        \caption{\href{https://realpython.com/python-ai-neural-network/}{Workflow} to train a model using supervised learning.}
        \label{Fig:ML}
    \end{figure}
\end{frame}

\begin{frame}{Supervised ML\cite{kroese2020}}
    \begin{itemize}
        \item Build models capable of learning from a series of data $X$.
        \item The learning process depends on the task we want to train the model:
            \begin{description}
                \item[Supervised] the input data $X$ is accompanied by the values ​$​y$ that we want the model to learn or also called targets (linear regression, decision trees, ...). The objective is that the prediction of the model given some data $x$ is equal to the target. 
                \item[Unsupervised] the task to be learned is some type of association of the input data $X$ with each other (i.e clustering).
            \end{description}
        \end{itemize}
\end{frame}


\begin{frame}{Feature engineering}
    \begin{figure}
        \includegraphics[width=0.9\linewidth]{FeatureEngineering}
        \caption{Feature engineering \href{https://realpython.com/python-ai-neural-network/}{example}.}
        \label{Fig:FeatureEngineering}
    \end{figure}
\end{frame}

\begin{frame}{Neural networks}
    \begin{itemize}
        \item In the ML example above, we use lemmatization to eliminate inflection from words, generating a simpler model.
        \item In neural networks, {\bf we leave the network itself} to find out the most important features in the data, without relying on feature engineering techniques. 
    \end{itemize}
    Neural Networks \href{https://towardsdatascience.com/deep-learning-with-python-neural-networks-complete-tutorial-6b53c0b06af0}{are based on} a collection of connected units (neurons), which, just like the synapses in a brain, can transmit a signal to other neurons, so that, acting like interconnected brain cells, they can learn and make decisions in a more human-like manner.\cite{nielsen_neural_2015}
\end{frame}

\begin{frame}{ML vs DL}
    \begin{figure}
        \includegraphics[width=0.7\linewidth]{MLvsDL}
        \caption{ML (fixed/engineered features + trainable classifier) vs DL (trainable feature extractor + trainable classifier). Source \href{https://blog.bismart.com/diferencia-machine-learning-deep-learning}{BISMART}. }
        \label{Fig:MLvsDL}
    \end{figure}
\end{frame}

\begin{frame}{Neural networks}
    \begin{figure}
        \includegraphics[width=0.9\linewidth]{2layerNN}
        \caption{ \href{https://realpython.com/python-ai-neural-network/}{Schema} of a 2 layer neural network.}
        \label{Fig:FeatureEngineering}
    \end{figure}
\end{frame}

\begin{frame}{Throwing darts and improving by learning}
    \begin{figure}
        \includegraphics[width=0.9\linewidth]{TrainingDart}
        \caption{\href{https://realpython.com/python-ai-neural-network/}{Steps} for trying to hit the center of a dartboard.}
        \label{Fig:TrainingDart}
    \end{figure}
\end{frame}


\begin{frame}{Artificial Neural Networks (ANN)}
    \begin{itemize}
        \item ANN are formed by layers of neurons.
        \item Each layer has a certain number of neurons.
        \item The input data $X$ enters through the first layer and through mathematical operations the input values are transformed into output values $y'$.
        \item The goal of the network is to modify the mathematical operations through some parameters (weights and biases, $W$ and $b$) to minimize the difference bewteen $y$ and $y'$.
        \item Deep Learning refers to all those models that use ANN of any type with multiple layers.
    \end{itemize}
\end{frame}



\begin{frame}{Perceptron}
    \begin{figure}
        \includegraphics[width=0.9\linewidth]{perceptron}
        \caption{$w_1 x_1 + w_2 x_2 +w_3x_3+w_4x_4 \leq \mathrm{threshold} \Rightarrow Y=0$. We can introduce bias and a given function: $\sigma(\uvec{w}\cdot \uvec{x}+b)=y'$. Adpated from \cite{rosenblatt_perceptron_1958}.}
        \label{Fig:perceptron}
    \end{figure}
\end{frame}

\begin{frame}{Multilayer perceptron}
    \begin{figure}
        \includegraphics[width=0.9\linewidth]{MLP}
        \caption{A multilayer perceptron with 5 hidden units.See also \href{https://youtu.be/aircAruvnKk?si=J6nqx_aSnjgYggvm}{this video}.}
        \label{Fig:perceptron}
    \end{figure}
\end{frame}

\begin{frame}{Multilayer perceptron: some maths}
    \small
    \[
        w^{L}_{ij}, \,
        \begin{cases}
            L = \mathrm{layer \ number} \\
            i = \mathrm{neuron \ from \ previous \ layer}\\
            j = \mathrm{neuron \ from \ following \ layer}  
        \end{cases}
    \]
    \[
        \sigma_1\left(\uvec{W}^{(1)^T} \cdot \uvec{X} + \uvec{b}^{(1)}\right) = 
        \sigma_1\left(
            \begin{bmatrix}
            w^{(1)}_{11} & w^{(1)}_{12} & w^{(1)}_{13} & w^{(1)}_{14}\\
            w^{(1)}_{21} & w^{(1)}_{22} & w^{(1)}_{23} & w^{(1)}_{24}\\
            w^{(1)}_{31} & w^{(1)}_{32} & w^{(1)}_{33} & w^{(1)}_{34}\\
            w^{(1)}_{41} & w^{(1)}_{42} & w^{(1)}_{43} & w^{(1)}_{44}\\
            w^{(1)}_{51} & w^{(1)}_{52} & w^{(1)}_{53} & w^{(1)}_{54}
            \end{bmatrix}
            \cdot
            \begin{bmatrix}
            x_{1}\\
            x_{2}\\
            x_{3}\\
            x_{4}
            \end{bmatrix}
            +
            \begin{bmatrix}
            b^{(1)}_{1}\\
            b^{(1)}_{2}\\
            b^{(1)}_{3}\\
            b^{(1)}_{4}\\
            b^{(1)}_{5}
            \end{bmatrix}
        \right) = 
        \uvec{H}^{(1)}
    \]
    \[
        \sigma_2\left(\uvec{W}^{(2)^T} \cdot  \uvec{H}^{(1)} + \uvec{b}^{(2)}\right)= 
        \sigma_2\left(\begin{bmatrix}
                w^{(2)}_{11} & w^{(2)}_{12} & w^{(2)}_{13} & w^{(2)}_{14} & w^{(2)}_{15}\\
                w^{(2)}_{21} & w^{(2)}_{22} & w^{(2)}_{23} & w^{(2)}_{24} & w^{(2)}_{25}\\
                w^{(2)}_{31} & w^{(2)}_{32} & w^{(2)}_{33} & w^{(2)}_{34} & w^{(2)}_{35}\\
                \end{bmatrix}
                \cdot
                \begin{bmatrix}
                h_{1}\\
                h_{2}\\
                h_{3}\\
                h_{4}\\
                h_{5}\\
                \end{bmatrix}
                +
                \begin{bmatrix}
                b^{(2)}_{1}\\
                b^{(2)}_{2}\\
                b^{(2)}_{3}\\
                \end{bmatrix}\right) 
                = \uvec{Y}^{\mathrm{out}}                    
    \]
    \normalsize
\end{frame}

\begin{frame}{Multilayer perceptron: some details}
    \begin{itemize}
        \item The MLP is the simplest neural network
        \item Weights connect neurons from an inner to an outer layer
        \item Operations in each layer are implemented using matrices and vectors
        \item The {\bf forward pass} of the last layer produces the ouput.
        \item The MLP can be interpreted as a multivariant function with $W$ and $b$ as the parameters, $X$ as input and $Y^{\mathrm{out}}$ as output.
        \item {\bf Hiperparameters} are additional parameters that control other aspects: number of layers, number of neurons per layer, acivation functions, ...
    \end{itemize}
\end{frame}

\begin{frame}{The logistic function}
    \begin{figure}
        \includegraphics[width=0.6\linewidth]{logistic}
        \caption{A binary classification problem. The class-conditional densities are Gaussians with unit $\sigma^2$. The posterior probability is the logistic function $y=1/(1+\exp{(-2x)})$\cite{jordan_why_1995}.}
        \label{Fig:logistic}
    \end{figure}
\end{frame}

\begin{frame}{Activation functions}
    \begin{columns}
        \begin{column}{0.4\linewidth}     
            \href{https://machinelearninggeek.com/activation-functions/}{Activation functions}:
            \begin{itemize}
                \item The {\bf sigmoid} function is used in the final layer in classification models.
                \item {\bf ReLU} is used in inner layers, as they produce non-linerity.
                \item All are differentiable. 
            \end{itemize}
        \end{column}
        \begin{column}{0.6\linewidth}
            \begin{figure}
                \includegraphics[width=0.8\linewidth]{activationfunctions}
            \end{figure}
        \end{column}
     \end{columns}
\end{frame}



\begin{frame}{An example of a 2 layer Neural Network}
    \begin{columns}
        \begin{column}{0.6\linewidth}     
            Example of classification (for categories "1" and "0") with a 2 layers NN. 
            \begin{itemize}
                \item In the first layer we use a linear regression approach.
                \item The second layer includes the non-linearity through the use of a \href{https://en.wikipedia.org/wiki/Sigmoid_function}{sigmoid function} that decides whether the prediction is 1 or 0, following the \href{https://en.wikipedia.org/wiki/Bernoulli_distribution}{Bernouilli distribution}.
            \end{itemize}
        \end{column}
        \begin{column}{0.4\linewidth}
            \begin{figure}
                \includegraphics[width=0.7\linewidth]{Training2Layer}
                \caption{\href{https://realpython.com/python-ai-neural-network/}{Training} a two layer neural network.}
                \label{Fig:Training2Layer}
            \end{figure}
        \end{column}
     \end{columns}
\end{frame}


\section{Cost and Backpropagation}

\begin{frame}
    \begin{Exercise}{Loss/Cost function in a simple 2 layer NN}
        \label{Ex:2layer}
        Check the \href{https://github.com/Biocomputing-Teaching/Data-Science-with-Python/blob/main/code/UNIT9-Neural-Networks.ipynb}{provided code} for this session and expand it to:
        \begin{enumerate}
            \item Generate a collection of 100 synthetic data points from a two Gaussian distribution.
            \item Assign the data points a category "0" or "1" depending on the Gaussian function they are obtained from.
            \item Use the provided 2 layers NN to evaluate the expected value of the loss function with the provided weights.
            \item Can you guess the weights that would improve the prediction (reducing the value of the error)?
        \end{enumerate}
    \end{Exercise}
\end{frame}

\begin{frame}[fragile]{Backpropagation: weights}
    \begin{columns}
        \begin{column}{0.6\linewidth}     
            {\bf Chain Rule in Backpropagation}In each {\bf backward pass}, you compute the partial derivatives of each function, substitute the variables by their values, and finally multiply everything.
            \\[10pt]
            Notice that, for the sigmoid function $f(x)=\frac{1}{1+e^{-x}}$, $f'(x)=1-f(x)$.
            \\[10pt]
            \begin{lstlisting}[language=Python]
derror_dweights = 
derror_dprediction 
* dprediction_dlayer1 
* dlayer1_dweights
            \end{lstlisting}
        \end{column}
        \begin{column}{0.4\linewidth}
            \begin{figure}
                \includegraphics[width=0.9\linewidth]{WeightGradient.png}
                \caption{\href{https://realpython.com/python-ai-neural-network/}{Chain rule:}  derivative of the  error with respect to {\bf weights}.}
                \label{Fig:Training2Layer}
            \end{figure}
        \end{column}
     \end{columns}
\end{frame}



\begin{frame}[fragile]{Backpropagation: bias}
    \begin{columns}
        \begin{column}{0.6\linewidth}  
            Chain rule applied to the derivative of the bias error in the 2 layer example.   
            \begin{lstlisting}[language=Python]
derror_dbias =  derror_dprediction 
* dprediction_dlayer1 
* dlayer1_dbias
            \end{lstlisting}
        \end{column}
        \begin{column}{0.4\linewidth}
            \begin{figure}
                \includegraphics[width=0.9\linewidth]{BiasGradient}
                \caption{\href{https://realpython.com/python-ai-neural-network/}{Chain rule:}  derivative of the error with respect to {\bf bias}.}
                \label{Fig:Training2Layer}
            \end{figure}
        \end{column}
     \end{columns}
\end{frame}

\section{NN layers}

\begin{frame}
    \frametitle{\href{https://cs.nyu.edu/~yann/talks/lecun-ranzato-icml2013.pdf}{Trainable feature hierarchy}}

    \begin{itemize}
        \item Increasing level of abstraction in hierarchy of representations
        \item Each stage is a kind of trainable feature transform
        \item Image recognition: Pixel $\rightarrow$ edge $\rightarrow$  texton $\rightarrow$  motif $\rightarrow$  part $\rightarrow$  objective
        \item Text: Character $\rightarrow$ word $\rightarrow$ word group $\rightarrow$ clause $\rightarrow$ sentence $\rightarrow$ story
        \item Speech: Sample $\rightarrow$  spectral band $\rightarrow$  sound $\rightarrow$ ... phoneme $\rightarrow$ word
    \end{itemize}
    

\end{frame}

\section{Convolutional Neural Networks}

\begin{frame}[fragile]{Convolutional Neural Networks}
    \begin{columns}
        \begin{column}{0.4\linewidth}  
            \begin{figure}
                \href{https://www.youtube.com/watch?v=FwFduRA_L6Q}{\includegraphics[width=0.9\linewidth]{CNNvideo}}
                \caption{Neural network for ZIP code recognition. To learn more: \cite{Olah_2014} and \href{https://distill.pub/}{distill}.}
                \label{Fig:CNNvideo}
            \end{figure}
        \end{column}
        \begin{column}{0.6\linewidth}
            \begin{figure}
                \includegraphics[width=0.9\linewidth]{CNN}
                \caption{Structure of the Lecun et al. neural network for ZIP code recognition\cite{lecun_backpropagation_1989}.}
                \label{Fig:CNN}
            \end{figure}
        \end{column}
     \end{columns}
\end{frame}

\begin{frame}
    \frametitle{CNN}
    \begin{itemize}
        \item Unlike traditional NN, which are fully connected, a CNN uses convolutional layers to learn features
        \item A CNN uses filters to extract features such as edges, corners or textures.
        \item It includes pooling layers, which downsample the output by taking the maximim or average value in a local neighborhood.
        \item Once the CNN layers have been passed, the data is flattened into a one-dimensional array that is input into one or more fully connected layers to predict from the learned features.
    \end{itemize}


    
\end{frame}

\begin{frame}
    \frametitle{Convolution and kernels}

    \begin{figure}[h]
        \centering
        \includegraphics[width=\linewidth]{convolution.png}
        \caption{Convolution between an input image and a kernel. Source \href{https://towardsdatascience.com/conv2d-to-finally-understand-what-happens-in-the-forward-pass-1bbaafb0b148}{TowardsDataScience}.}
        \label{<label>}
    \end{figure}

\end{frame}

\begin{frame}
    \frametitle{Kernels}

    The trainable parameters in a CNN are all the parameters that will be updated when the network is trained. In a Conv2D, the trainable elements are the values that compose the kernels. In a $3\times 3$ convolution kernel, we have $3\cdot 3=9$ trainable parameters plus, eventually, a biass (for a complete explanation, check \href{https://towardsdatascience.com/conv2d-to-finally-understand-what-happens-in-the-forward-pass-1bbaafb0b148}{this link}):
    \[
    \omega\cdot F(x,y)= \omega_{bias}+\sum_{\delta x=-k_i}^{k_i}  \sum_{\delta y=-k_j}^{k_j}
    \omega(\delta x,\delta y)\cdot F(x+\delta x,y + \delta y)
    \]
    The number of parameters increases linearly with the number of convolution kernels. Hence linearly with the number of desired output channels. 

\end{frame}


\begin{frame}
    \frametitle{The MNIST Handwritten Digit Classification Dataset}
    \begin{itemize}
        \item The MNIST dataset is an acronym that stands for the Modified National Institute of Standards and Technology dataset.
        \item It contains 60,000 small square 28×28 pixel grayscale images of handwritten single digits between 0 and 9.
        \item The task is to classify a given image of a handwritten digit into one of 10 classes representing integer values from 0 to 9, inclusively.
        \item  Top-performing models are deep learning convolutional neural networks that achieve a classification accuracy of above 99\%, with an error rate between 0.4\% and 0.2\% on the hold out test dataset.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Keras vs Tensorflow vs pytorch}
% https://www.simplilearn.com/keras-vs-tensorflow-vs-pytorch-article
    \begin{description}
        \item[Tensorflow] Low-level software library created by Google to implement ML and to solve complex numerical problems. Every element is converted into a graphical form. The variables in the graph are tensors and the operations are called {\em operators}. Tensors are unmutable. High productivity.
        \item[Keras] High-level deep learning API written in Python for easy implementation and computation of neural newtworks. Keras uses Tensorflow as its low-level engine.
        \item[Pytorch] Low-level API developed by Facebook for natural language processing and computer vision. More powerful than numpy. Most popular among researchers.
    \end{description}
\end{frame}



% nous temes:
% -encoding/decoding
% -RFECV
% -computer vision
% -training NN (iceland 8)
% -CNN (iceland 9)
% -GAN
% -tensorflow vs pytorch vs keras
% -recommender

\section{Bibliography}

\bibliographystyle{unsrt}
\bibliography{DataSciencewithPython}
\end{document}
